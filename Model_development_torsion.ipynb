{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Bio import SeqIO\n",
    "from utils import preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "import models\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "path = '../Data_Sets/PDB/FASTA'\n",
    "file_name_m = 'mask_3.fasta'\n",
    "file_name_t = 'mask_torsion.fasta'\n",
    "dict_ = {'id':[] ,'mask':[],'seq':[], 'mask_bin':[], 'seq_bin':[], 'loss_weight':[], 'seq_int':[], 'coord':[], 'angle':[]}\n",
    "count = 0\n",
    "seq_length = 1024\n",
    "d = {'H':1/0.372, 'B':1/0.2105, 'C':1/0.4173}\n",
    "for i, rec in enumerate(SeqIO.parse(os.path.join(path,file_name_m),'fasta')):\n",
    "    \n",
    "    if i >5000:\n",
    "        break\n",
    "    if len(rec.seq)>seq_length:\n",
    "        continue\n",
    "        \n",
    "    #print(rec.id)\n",
    "    dict_['id'].append(rec.id)\n",
    "    dict_['seq'].append(rec.seq)\n",
    "    dict_['seq_int'].append(pre.to_int(rec.seq, max_length=seq_length))\n",
    "    \n",
    "    \n",
    "    \n",
    "    dict_['mask'].append(rec.description.split('|lcl|')[:len(rec.seq)])\n",
    "    dict_['mask_bin'].append(pre.to_binary_mask(pre.mask_padding(rec.description.split('|lcl|')[-1], length=seq_length)))\n",
    "    dict_['loss_weight'].append(pre.loss_weight(rec.description.split('|lcl|')[-1][:len(rec.seq)], d,seq_length))\n",
    "\n",
    "    \n",
    "for k, rec in enumerate(SeqIO.parse(os.path.join(path,file_name_t),'fasta')):\n",
    "        \n",
    "    if k >5000:\n",
    "        break\n",
    "    if len(rec.seq)>seq_length:\n",
    "        continue\n",
    "    #print(rec.id)\n",
    "\n",
    "\n",
    "    f = np.array([ j.split(',')[1:] for j in rec.description.split('|lcl|')[-1].split(';')][1:], dtype=np.float32)\n",
    "    f = ((360+f)%360)/180 * np.pi - np.pi\n",
    "    dict_['angle'].append(pre.zero_padding(f,length=seq_length))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(dict_['seq_int'], dtype = np.int8 ), np.array(dict_['angle'], dtype = np.float32), test_size=0.1, random_state=42)\n",
    "id_train, id_test, seq_train, seq_test = train_test_split(dict_['id'], dict_['seq'], test_size=0.1, random_state=42)\n",
    "W_train, W_test, M_train, M_test = train_test_split(dict_['loss_weight'], dict_['mask_bin'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.1415927 , -0.06806827],\n",
       "       [ 0.8237953 , -2.1170843 ],\n",
       "       [ 1.9041545 ,  2.820452  ],\n",
       "       [ 1.839577  ,  2.6040318 ],\n",
       "       [ 2.1642082 ,  2.5342185 ],\n",
       "       [ 2.0420353 ,  2.490585  ],\n",
       "       [ 1.727876  , -0.32812166],\n",
       "       [ 1.907645  ,  2.9024823 ],\n",
       "       [ 2.2916172 ,  2.3998277 ],\n",
       "       [ 2.0036376 ,  2.6755893 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0,:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "build (None, 64, 256)\n",
      "build (None, 128, 256)\n",
      "build (None, 256, 128)\n",
      "build (None, 512, 64)\n",
      "build (None, 64, 256)\n",
      "build (None, 128, 256)\n",
      "build (None, 256, 128)\n",
      "build (None, 512, 64)\n",
      "Train on 196422 samples, validate on 21825 samples\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 203 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:batch_all_reduce: 203 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "196422/196422 [==============================] - 529s 3ms/sample - loss: 0.7596 - model_loss: 0.5540 - model_1_loss: 0.0363 - val_loss: 0.9591 - val_model_loss: 0.7401 - val_model_1_loss: 0.0126\n",
      "Epoch 2/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.7638 - model_loss: 0.5539 - model_1_loss: 0.0461 - val_loss: 0.7084 - val_model_loss: 0.6143 - val_model_1_loss: 0.0383\n",
      "Epoch 3/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.7936 - model_loss: 0.5537 - model_1_loss: 0.0425 - val_loss: 0.9632 - val_model_loss: 0.5900 - val_model_1_loss: 0.0382\n",
      "Epoch 4/100\n",
      "196422/196422 [==============================] - 473s 2ms/sample - loss: 0.7952 - model_loss: 0.5540 - model_1_loss: 0.0408 - val_loss: 0.7473 - val_model_loss: 0.6578 - val_model_1_loss: 0.0229\n",
      "Epoch 5/100\n",
      "196422/196422 [==============================] - 472s 2ms/sample - loss: 0.8021 - model_loss: 0.5538 - model_1_loss: 0.0458 - val_loss: 1.1023 - val_model_loss: 0.7018 - val_model_1_loss: 0.0230\n",
      "Epoch 6/100\n",
      "196422/196422 [==============================] - 471s 2ms/sample - loss: 0.7969 - model_loss: 0.5537 - model_1_loss: 0.0403 - val_loss: 0.8457 - val_model_loss: 0.6700 - val_model_1_loss: 0.0382\n",
      "Epoch 7/100\n",
      "196422/196422 [==============================] - 471s 2ms/sample - loss: 0.8080 - model_loss: 0.5540 - model_1_loss: 0.0500 - val_loss: 0.8225 - val_model_loss: 0.7435 - val_model_1_loss: 0.0383\n",
      "Epoch 8/100\n",
      "196422/196422 [==============================] - 472s 2ms/sample - loss: 0.7941 - model_loss: 0.5537 - model_1_loss: 0.0444 - val_loss: 0.8844 - val_model_loss: 0.7231 - val_model_1_loss: 0.0185\n",
      "Epoch 9/100\n",
      "196422/196422 [==============================] - 471s 2ms/sample - loss: 0.7897 - model_loss: 0.5541 - model_1_loss: 0.0507 - val_loss: 1.1391 - val_model_loss: 0.7025 - val_model_1_loss: 0.0777\n",
      "Epoch 10/100\n",
      "196422/196422 [==============================] - 471s 2ms/sample - loss: 0.8265 - model_loss: 0.5543 - model_1_loss: 0.0470 - val_loss: 0.7627 - val_model_loss: 0.6470 - val_model_1_loss: 0.0230\n",
      "Epoch 11/100\n",
      "196422/196422 [==============================] - 472s 2ms/sample - loss: 0.8143 - model_loss: 0.5538 - model_1_loss: 0.0514 - val_loss: 1.0620 - val_model_loss: 0.7499 - val_model_1_loss: 0.0448\n",
      "Epoch 12/100\n",
      "196422/196422 [==============================] - 471s 2ms/sample - loss: 0.8465 - model_loss: 0.5541 - model_1_loss: 0.0493 - val_loss: 1.1709 - val_model_loss: 0.6567 - val_model_1_loss: 0.0141\n",
      "Epoch 13/100\n",
      "196422/196422 [==============================] - 470s 2ms/sample - loss: 0.8502 - model_loss: 0.5543 - model_1_loss: 0.0369 - val_loss: 0.8698 - val_model_loss: 0.7543 - val_model_1_loss: 0.0297\n",
      "Epoch 14/100\n",
      "196422/196422 [==============================] - 467s 2ms/sample - loss: 0.8779 - model_loss: 0.5541 - model_1_loss: 0.0453 - val_loss: 0.7571 - val_model_loss: 0.6845 - val_model_1_loss: 0.0383\n",
      "Epoch 15/100\n",
      "196422/196422 [==============================] - 468s 2ms/sample - loss: 0.8517 - model_loss: 0.5540 - model_1_loss: 0.0432 - val_loss: 1.2020 - val_model_loss: 0.7458 - val_model_1_loss: 0.0380\n",
      "Epoch 16/100\n",
      "196422/196422 [==============================] - 467s 2ms/sample - loss: 0.8440 - model_loss: 0.5539 - model_1_loss: 0.0430 - val_loss: 0.9397 - val_model_loss: 0.7659 - val_model_1_loss: 0.0387\n",
      "Epoch 17/100\n",
      "196422/196422 [==============================] - 465s 2ms/sample - loss: 0.8250 - model_loss: 0.5540 - model_1_loss: 0.0483 - val_loss: 1.2616 - val_model_loss: 0.7378 - val_model_1_loss: 0.0322\n",
      "Epoch 18/100\n",
      "196422/196422 [==============================] - 466s 2ms/sample - loss: 0.9015 - model_loss: 0.5539 - model_1_loss: 0.0497 - val_loss: 0.9997 - val_model_loss: 0.6574 - val_model_1_loss: 0.0572\n",
      "Epoch 19/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8590 - model_loss: 0.5542 - model_1_loss: 0.0445 - val_loss: 0.9337 - val_model_loss: 0.6971 - val_model_1_loss: 0.0382\n",
      "Epoch 20/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8381 - model_loss: 0.5539 - model_1_loss: 0.0450 - val_loss: 0.9620 - val_model_loss: 0.7386 - val_model_1_loss: 0.0221\n",
      "Epoch 21/100\n",
      "196422/196422 [==============================] - 461s 2ms/sample - loss: 0.7972 - model_loss: 0.5539 - model_1_loss: 0.0446 - val_loss: 0.9451 - val_model_loss: 0.7100 - val_model_1_loss: 0.0390\n",
      "Epoch 22/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8433 - model_loss: 0.5539 - model_1_loss: 0.0463 - val_loss: 1.0247 - val_model_loss: 0.7527 - val_model_1_loss: 0.0223\n",
      "Epoch 23/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8385 - model_loss: 0.5539 - model_1_loss: 0.0361 - val_loss: 0.8214 - val_model_loss: 0.7375 - val_model_1_loss: 0.0176\n",
      "Epoch 24/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8695 - model_loss: 0.5544 - model_1_loss: 0.0427 - val_loss: 0.9981 - val_model_loss: 0.6737 - val_model_1_loss: 0.0381\n",
      "Epoch 25/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8278 - model_loss: 0.5542 - model_1_loss: 0.0475 - val_loss: 0.7555 - val_model_loss: 0.6788 - val_model_1_loss: 0.0382\n",
      "Epoch 26/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8612 - model_loss: 0.5544 - model_1_loss: 0.0476 - val_loss: 0.8069 - val_model_loss: 0.6375 - val_model_1_loss: 0.0357\n",
      "Epoch 27/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8829 - model_loss: 0.5541 - model_1_loss: 0.0503 - val_loss: 1.1063 - val_model_loss: 0.7479 - val_model_1_loss: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "196422/196422 [==============================] - 466s 2ms/sample - loss: 0.8786 - model_loss: 0.5543 - model_1_loss: 0.0543 - val_loss: 0.9523 - val_model_loss: 0.7534 - val_model_1_loss: 0.0382\n",
      "Epoch 29/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8966 - model_loss: 0.5546 - model_1_loss: 0.0431 - val_loss: 0.9389 - val_model_loss: 0.7534 - val_model_1_loss: 0.0125\n",
      "Epoch 30/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8818 - model_loss: 0.5541 - model_1_loss: 0.0438 - val_loss: 0.8027 - val_model_loss: 0.6101 - val_model_1_loss: 0.0230\n",
      "Epoch 31/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.9077 - model_loss: 0.5544 - model_1_loss: 0.0475 - val_loss: 0.8782 - val_model_loss: 0.7456 - val_model_1_loss: 0.0125\n",
      "Epoch 32/100\n",
      "196422/196422 [==============================] - 467s 2ms/sample - loss: 0.8841 - model_loss: 0.5540 - model_1_loss: 0.0471 - val_loss: 0.7756 - val_model_loss: 0.6830 - val_model_1_loss: 0.0230\n",
      "Epoch 33/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8465 - model_loss: 0.5542 - model_1_loss: 0.0490 - val_loss: 1.1171 - val_model_loss: 0.6941 - val_model_1_loss: 0.0381\n",
      "Epoch 34/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8922 - model_loss: 0.5542 - model_1_loss: 0.0409 - val_loss: 0.9081 - val_model_loss: 0.7531 - val_model_1_loss: 0.0212\n",
      "Epoch 35/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8663 - model_loss: 0.5539 - model_1_loss: 0.0455 - val_loss: 0.8273 - val_model_loss: 0.6108 - val_model_1_loss: 0.0898\n",
      "Epoch 36/100\n",
      "196422/196422 [==============================] - 461s 2ms/sample - loss: 0.8502 - model_loss: 0.5538 - model_1_loss: 0.0464 - val_loss: 0.8152 - val_model_loss: 0.7400 - val_model_1_loss: 0.0384\n",
      "Epoch 37/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8555 - model_loss: 0.5536 - model_1_loss: 0.0497 - val_loss: 1.1470 - val_model_loss: 0.7689 - val_model_1_loss: 0.0864\n",
      "Epoch 38/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8795 - model_loss: 0.5540 - model_1_loss: 0.0486 - val_loss: 0.8340 - val_model_loss: 0.7707 - val_model_1_loss: 0.0381\n",
      "Epoch 39/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8112 - model_loss: 0.5536 - model_1_loss: 0.0510 - val_loss: 0.9753 - val_model_loss: 0.7534 - val_model_1_loss: 0.0387\n",
      "Epoch 40/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8106 - model_loss: 0.5541 - model_1_loss: 0.0488 - val_loss: 0.8962 - val_model_loss: 0.7393 - val_model_1_loss: 0.0589\n",
      "Epoch 41/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8919 - model_loss: 0.5538 - model_1_loss: 0.0460 - val_loss: 1.3472 - val_model_loss: 0.7083 - val_model_1_loss: 0.0194\n",
      "Epoch 42/100\n",
      "196422/196422 [==============================] - 461s 2ms/sample - loss: 0.8405 - model_loss: 0.5537 - model_1_loss: 0.0494 - val_loss: 0.8863 - val_model_loss: 0.7712 - val_model_1_loss: 0.0229\n",
      "Epoch 43/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8559 - model_loss: 0.5538 - model_1_loss: 0.0515 - val_loss: 1.2493 - val_model_loss: 0.7534 - val_model_1_loss: 0.0160\n",
      "Epoch 44/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8977 - model_loss: 0.5540 - model_1_loss: 0.0467 - val_loss: 1.0487 - val_model_loss: 0.7534 - val_model_1_loss: 0.0793\n",
      "Epoch 45/100\n",
      "196422/196422 [==============================] - 461s 2ms/sample - loss: 0.8604 - model_loss: 0.5535 - model_1_loss: 0.0421 - val_loss: 0.9354 - val_model_loss: 0.7650 - val_model_1_loss: 0.0296\n",
      "Epoch 46/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8719 - model_loss: 0.5535 - model_1_loss: 0.0481 - val_loss: 1.4869 - val_model_loss: 0.6955 - val_model_1_loss: 0.0384\n",
      "Epoch 47/100\n",
      "196422/196422 [==============================] - 456s 2ms/sample - loss: 0.8719 - model_loss: 0.5547 - model_1_loss: 0.0492 - val_loss: 0.8647 - val_model_loss: 0.7534 - val_model_1_loss: 0.0383\n",
      "Epoch 48/100\n",
      "196422/196422 [==============================] - 456s 2ms/sample - loss: 0.8621 - model_loss: 0.5541 - model_1_loss: 0.0460 - val_loss: 0.8767 - val_model_loss: 0.6351 - val_model_1_loss: 0.0775\n",
      "Epoch 49/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8793 - model_loss: 0.5542 - model_1_loss: 0.0481 - val_loss: 0.9651 - val_model_loss: 0.6146 - val_model_1_loss: 0.0381\n",
      "Epoch 50/100\n",
      "196422/196422 [==============================] - 462s 2ms/sample - loss: 0.8675 - model_loss: 0.5540 - model_1_loss: 0.0519 - val_loss: 0.7122 - val_model_loss: 0.6134 - val_model_1_loss: 0.0386\n",
      "Epoch 51/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8725 - model_loss: 0.5537 - model_1_loss: 0.0507 - val_loss: 0.7630 - val_model_loss: 0.6837 - val_model_1_loss: 0.0382\n",
      "Epoch 52/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8643 - model_loss: 0.5538 - model_1_loss: 0.0442 - val_loss: 1.3074 - val_model_loss: 0.6442 - val_model_1_loss: 0.0273\n",
      "Epoch 53/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8351 - model_loss: 0.5536 - model_1_loss: 0.0410 - val_loss: 0.7363 - val_model_loss: 0.6647 - val_model_1_loss: 0.0358\n",
      "Epoch 54/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8336 - model_loss: 0.5541 - model_1_loss: 0.0465 - val_loss: 1.0786 - val_model_loss: 0.6805 - val_model_1_loss: 0.0385\n",
      "Epoch 55/100\n",
      "196422/196422 [==============================] - 455s 2ms/sample - loss: 0.8891 - model_loss: 0.5535 - model_1_loss: 0.0534 - val_loss: 1.3097 - val_model_loss: 0.7406 - val_model_1_loss: 0.0352\n",
      "Epoch 56/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8190 - model_loss: 0.5536 - model_1_loss: 0.0506 - val_loss: 0.9510 - val_model_loss: 0.7467 - val_model_1_loss: 0.0147\n",
      "Epoch 57/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8248 - model_loss: 0.5540 - model_1_loss: 0.0429 - val_loss: 0.6723 - val_model_loss: 0.6163 - val_model_1_loss: 0.0230\n",
      "Epoch 58/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.9194 - model_loss: 0.5530 - model_1_loss: 0.0522 - val_loss: 0.9861 - val_model_loss: 0.7107 - val_model_1_loss: 0.0551\n",
      "Epoch 59/100\n",
      "196422/196422 [==============================] - 465s 2ms/sample - loss: 1.0010 - model_loss: 0.5530 - model_1_loss: 0.0509 - val_loss: 1.1315 - val_model_loss: 0.7509 - val_model_1_loss: 0.0263\n",
      "Epoch 60/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8678 - model_loss: 0.5537 - model_1_loss: 0.0514 - val_loss: 1.2223 - val_model_loss: 0.7434 - val_model_1_loss: 0.0131\n",
      "Epoch 61/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8943 - model_loss: 0.5538 - model_1_loss: 0.0531 - val_loss: 0.8403 - val_model_loss: 0.7444 - val_model_1_loss: 0.0381\n",
      "Epoch 62/100\n",
      "196422/196422 [==============================] - 461s 2ms/sample - loss: 0.8739 - model_loss: 0.5538 - model_1_loss: 0.0491 - val_loss: 0.8338 - val_model_loss: 0.6994 - val_model_1_loss: 0.0282\n",
      "Epoch 63/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8811 - model_loss: 0.5535 - model_1_loss: 0.0529 - val_loss: 1.0663 - val_model_loss: 0.7648 - val_model_1_loss: 0.0357\n",
      "Epoch 64/100\n",
      "196422/196422 [==============================] - 461s 2ms/sample - loss: 0.9176 - model_loss: 0.5537 - model_1_loss: 0.0437 - val_loss: 1.2672 - val_model_loss: 0.7549 - val_model_1_loss: 0.0229\n",
      "Epoch 65/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.9393 - model_loss: 0.5540 - model_1_loss: 0.0454 - val_loss: 0.9447 - val_model_loss: 0.7527 - val_model_1_loss: 0.0384\n",
      "Epoch 66/100\n",
      "196422/196422 [==============================] - 462s 2ms/sample - loss: 0.9117 - model_loss: 0.5537 - model_1_loss: 0.0490 - val_loss: 0.7028 - val_model_loss: 0.5823 - val_model_1_loss: 0.0229\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.9397 - model_loss: 0.5538 - model_1_loss: 0.0471 - val_loss: 1.0228 - val_model_loss: 0.7479 - val_model_1_loss: 0.0230\n",
      "Epoch 68/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.9422 - model_loss: 0.5540 - model_1_loss: 0.0486 - val_loss: 1.4324 - val_model_loss: 0.7641 - val_model_1_loss: 0.0906\n",
      "Epoch 69/100\n",
      "196422/196422 [==============================] - 463s 2ms/sample - loss: 0.8109 - model_loss: 0.5534 - model_1_loss: 0.0487 - val_loss: 0.8125 - val_model_loss: 0.7474 - val_model_1_loss: 0.0382\n",
      "Epoch 70/100\n",
      "196422/196422 [==============================] - 466s 2ms/sample - loss: 0.8659 - model_loss: 0.5531 - model_1_loss: 0.0513 - val_loss: 0.9962 - val_model_loss: 0.7528 - val_model_1_loss: 0.0312\n",
      "Epoch 71/100\n",
      "196422/196422 [==============================] - 466s 2ms/sample - loss: 0.9103 - model_loss: 0.5533 - model_1_loss: 0.0480 - val_loss: 1.0600 - val_model_loss: 0.7704 - val_model_1_loss: 0.0859\n",
      "Epoch 72/100\n",
      "196422/196422 [==============================] - 465s 2ms/sample - loss: 0.8345 - model_loss: 0.5543 - model_1_loss: 0.0449 - val_loss: 1.0135 - val_model_loss: 0.7042 - val_model_1_loss: 0.0389\n",
      "Epoch 73/100\n",
      "196422/196422 [==============================] - 467s 2ms/sample - loss: 0.8673 - model_loss: 0.5538 - model_1_loss: 0.0494 - val_loss: 0.9935 - val_model_loss: 0.7271 - val_model_1_loss: 0.0266\n",
      "Epoch 74/100\n",
      "196422/196422 [==============================] - 462s 2ms/sample - loss: 0.8536 - model_loss: 0.5538 - model_1_loss: 0.0514 - val_loss: 1.0415 - val_model_loss: 0.7683 - val_model_1_loss: 0.0252\n",
      "Epoch 75/100\n",
      "196422/196422 [==============================] - 460s 2ms/sample - loss: 0.8549 - model_loss: 0.5544 - model_1_loss: 0.0301 - val_loss: 0.8584 - val_model_loss: 0.6491 - val_model_1_loss: 0.0357\n",
      "Epoch 76/100\n",
      "196422/196422 [==============================] - 459s 2ms/sample - loss: 0.8571 - model_loss: 0.5535 - model_1_loss: 0.0456 - val_loss: 1.0276 - val_model_loss: 0.7458 - val_model_1_loss: 0.0281\n",
      "Epoch 77/100\n",
      "196422/196422 [==============================] - 462s 2ms/sample - loss: 0.8787 - model_loss: 0.5544 - model_1_loss: 0.0442 - val_loss: 1.2890 - val_model_loss: 0.7053 - val_model_1_loss: 0.0303\n",
      "Epoch 78/100\n",
      "196422/196422 [==============================] - 462s 2ms/sample - loss: 0.8744 - model_loss: 0.5550 - model_1_loss: 0.0527 - val_loss: 0.9189 - val_model_loss: 0.7500 - val_model_1_loss: 0.0229\n",
      "Epoch 79/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8923 - model_loss: 0.5538 - model_1_loss: 0.0439 - val_loss: 0.8002 - val_model_loss: 0.7367 - val_model_1_loss: 0.0230\n",
      "Epoch 80/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8805 - model_loss: 0.5535 - model_1_loss: 0.0380 - val_loss: 1.1010 - val_model_loss: 0.7489 - val_model_1_loss: 0.0128\n",
      "Epoch 81/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8450 - model_loss: 0.5534 - model_1_loss: 0.0475 - val_loss: 1.2771 - val_model_loss: 0.7714 - val_model_1_loss: 0.0376\n",
      "Epoch 82/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8771 - model_loss: 0.5534 - model_1_loss: 0.0332 - val_loss: 0.9846 - val_model_loss: 0.7703 - val_model_1_loss: 0.0356\n",
      "Epoch 83/100\n",
      "196422/196422 [==============================] - 465s 2ms/sample - loss: 0.8087 - model_loss: 0.5542 - model_1_loss: 0.0345 - val_loss: 1.3044 - val_model_loss: 0.7173 - val_model_1_loss: 0.0347\n",
      "Epoch 84/100\n",
      "196422/196422 [==============================] - 464s 2ms/sample - loss: 0.8878 - model_loss: 0.5545 - model_1_loss: 0.0461 - val_loss: 1.6074 - val_model_loss: 0.7683 - val_model_1_loss: 0.0721\n",
      "Epoch 85/100\n",
      "196422/196422 [==============================] - 462s 2ms/sample - loss: 0.8870 - model_loss: 0.5542 - model_1_loss: 0.0518 - val_loss: 1.9389 - val_model_loss: 0.7366 - val_model_1_loss: 0.0384\n",
      "Epoch 86/100\n",
      "196422/196422 [==============================] - 465s 2ms/sample - loss: 0.8399 - model_loss: 0.5537 - model_1_loss: 0.0425 - val_loss: 0.9456 - val_model_loss: 0.7534 - val_model_1_loss: 0.0294\n",
      "Epoch 87/100\n",
      "196422/196422 [==============================] - 476s 2ms/sample - loss: 0.8611 - model_loss: 0.5539 - model_1_loss: 0.0397 - val_loss: 1.0329 - val_model_loss: 0.7703 - val_model_1_loss: 0.0223\n",
      "Epoch 88/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8886 - model_loss: 0.5541 - model_1_loss: 0.0415 - val_loss: 0.9536 - val_model_loss: 0.7707 - val_model_1_loss: 0.0355\n",
      "Epoch 89/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8471 - model_loss: 0.5538 - model_1_loss: 0.0518 - val_loss: 0.8300 - val_model_loss: 0.7039 - val_model_1_loss: 0.0377\n",
      "Epoch 90/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8404 - model_loss: 0.5546 - model_1_loss: 0.0485 - val_loss: 0.9444 - val_model_loss: 0.7501 - val_model_1_loss: 0.0155\n",
      "Epoch 91/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8608 - model_loss: 0.5537 - model_1_loss: 0.0513 - val_loss: 0.8622 - val_model_loss: 0.7104 - val_model_1_loss: 0.0389\n",
      "Epoch 92/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8694 - model_loss: 0.5538 - model_1_loss: 0.0488 - val_loss: 0.9296 - val_model_loss: 0.6445 - val_model_1_loss: 0.0571\n",
      "Epoch 93/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8792 - model_loss: 0.5535 - model_1_loss: 0.0501 - val_loss: 0.7717 - val_model_loss: 0.6938 - val_model_1_loss: 0.0383\n",
      "Epoch 94/100\n",
      "196422/196422 [==============================] - 474s 2ms/sample - loss: 0.8961 - model_loss: 0.5536 - model_1_loss: 0.0532 - val_loss: 1.3026 - val_model_loss: 0.7705 - val_model_1_loss: 0.0402\n",
      "Epoch 95/100\n",
      "196422/196422 [==============================] - 475s 2ms/sample - loss: 0.8808 - model_loss: 0.5534 - model_1_loss: 0.0470 - val_loss: 1.3369 - val_model_loss: 0.7590 - val_model_1_loss: 0.0384\n",
      "Epoch 96/100\n",
      "196422/196422 [==============================] - 477s 2ms/sample - loss: 0.8956 - model_loss: 0.5537 - model_1_loss: 0.0489 - val_loss: 1.1364 - val_model_loss: 0.7213 - val_model_1_loss: 0.0415\n",
      "Epoch 97/100\n",
      "196422/196422 [==============================] - 478s 2ms/sample - loss: 0.8861 - model_loss: 0.5533 - model_1_loss: 0.0500 - val_loss: 1.0768 - val_model_loss: 0.5776 - val_model_1_loss: 0.0331\n",
      "Epoch 98/100\n",
      "196422/196422 [==============================] - 478s 2ms/sample - loss: 0.8935 - model_loss: 0.5540 - model_1_loss: 0.0540 - val_loss: 1.4869 - val_model_loss: 0.6507 - val_model_1_loss: 0.0527\n",
      "Epoch 99/100\n",
      "196422/196422 [==============================] - 477s 2ms/sample - loss: 0.8668 - model_loss: 0.5535 - model_1_loss: 0.0496 - val_loss: 0.9380 - val_model_loss: 0.7079 - val_model_1_loss: 0.0562\n",
      "Epoch 100/100\n",
      "196422/196422 [==============================] - 478s 2ms/sample - loss: 0.9202 - model_loss: 0.5536 - model_1_loss: 0.0486 - val_loss: 1.1575 - val_model_loss: 0.7398 - val_model_1_loss: 0.0337\n"
     ]
    }
   ],
   "source": [
    "p1 = {'max_seq_len': seq_length,\n",
    "     'num_classes': 3,\n",
    "     'emb_size': 20,\n",
    "     'num_filter': [32, 64, 128, 256, 512],\n",
    "     'kernel_size':[4, 4, 4, 4, 4] ,\n",
    "     'sampling_stride': [2, 2, 2, 2],\n",
    "     'pool_size': [2, 2, 2, 2, 2, 2],\n",
    "     'rate': [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "     'l1': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "     'l2': [0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "     'use_max_pool': False,\n",
    "     'learning_rate': 1e-4,\n",
    "    'output_activation': 'softmax'}\n",
    "p2 = {'max_seq_len': seq_length,\n",
    "     'num_classes': 32,\n",
    "     'emb_size': 10,\n",
    "     'num_filter': [32, 64, 128, 256, 512],\n",
    "     'kernel_size':[4, 4, 4, 4, 4] ,\n",
    "     'sampling_stride': [2, 2, 2, 2],\n",
    "     'pool_size': [2, 2, 2, 2, 2, 2],\n",
    "     'rate': [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "     'l1': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "     'l2': [0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "     'use_max_pool': False,\n",
    "     'learning_rate': 1e-4,\n",
    "    'output_activation': 'softmax',\n",
    "     'features':32}\n",
    "\n",
    "\n",
    "class TorsionLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, size):\n",
    "        super(TorsionLoss,self).__init__()\n",
    "        self.size = size\n",
    "        self.flatten = tf.keras.layers.Flatten()  \n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        y_true = tf.transpose(y_true, perm=[0,2,1])\n",
    "        y_pred = tf.transpose(y_pred, perm=[0,2,1])\n",
    "        \n",
    "\n",
    "        y_true_csum = tf.keras.backend.cumsum(y_true, axis=-1)\n",
    "        y_pred_csum = tf.keras.backend.cumsum(y_pred, axis=-1)\n",
    "\n",
    "        \n",
    "        y_true_mat_0 = tf.keras.backend.repeat(y_true_csum[:,0,:], self.size)\n",
    "        y_true_mat_1 = tf.keras.backend.repeat(y_true_csum[:,1,:], self.size)\n",
    "        y_pred_mat_0 = tf.keras.backend.repeat(y_pred_csum[:,0,:], self.size)\n",
    "        y_pred_mat_1 = tf.keras.backend.repeat(y_pred_csum[:,1,:], self.size)\n",
    "        \n",
    "\n",
    "        y_pred_mat_0 = tf.transpose(y_pred_mat_0, perm=[0,2,1])\n",
    "        y_pred_mat_1 = tf.transpose(y_pred_mat_1, perm=[0,2,1])\n",
    "\n",
    "        vec_0 = tf.math.squared_difference(y_true_mat_0,y_pred_mat_0)\n",
    "        vec_1 = tf.math.squared_difference(y_true_mat_1,y_pred_mat_1)\n",
    "        \n",
    "        dist_mat = tf.math.sqrt(tf.math.add(vec_0, vec_1))\n",
    "        loss = tf.math.reduce_sum(tf.math.l2_normalize(dist_mat),axis=-1)\n",
    "        return loss\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model1 = models.res_u_net(p1)\n",
    "    model2 = models.res_u_net_tor(p2)\n",
    "\n",
    "\n",
    "    model1.load_weights('Weights_MaskModel/w_LDataset')\n",
    "\n",
    "    inp1 = tf.keras.layers.Input(shape=(seq_length))\n",
    "    out1, x_o = model1(inp1)\n",
    "    x1 = tf.keras.layers.Conv1D(32, 7, padding='same')(out1)\n",
    "    x2 = tf.keras.layers.Conv1D(32, 7, padding='same')(x_o)\n",
    "    inp2 = tf.keras.layers.Add()([x1,x2])\n",
    "    out2 = model2(inp2)\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs = inp1, outputs = [out1,out2])\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    loss = TorsionLoss(size=1024)\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    add = tf.keras.optimizers.Adam(learning_rate=1e-4,name='Adam_1')\n",
    "\n",
    "\n",
    "\n",
    "    model.load_weights('Weights_MaskModel/w_tor_mod')\n",
    "    # compiling and fitting with Adam optimizer\n",
    "    model.compile(optimizer = add, loss = [cce, loss], sample_weight_mode=\"temporal\")\n",
    "    his = []\n",
    "    li1 = []\n",
    "\n",
    "    for u in range(10):\n",
    "        his.append(model.fit(X_train, [M_train, Y_train], batch_size=128,\n",
    "                             epochs= 100, validation_split=0.1,\n",
    "                             sample_weight = [ np.array(W_train),np.array(W_train)]))\n",
    "\n",
    "        model.save_weights('Weights_MaskModel/w_tor_mod')\n",
    "    #li1.append(model.evaluate(x = X_test, y = [M_test,Y_test], batch_size=64, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Weights_MaskModel/w_tor_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.load_weights('Weights_MaskModel/w_tor_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9ff149d6fbd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_model_1_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.plot(his[1].history['loss'])\n",
    "ax1.plot(his[1].history['val_loss'])\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.plot(his[0].history['val_model_1_loss'])\n",
    "ax2.set_ylim([0,1])\n",
    "plt.show()\n",
    "#ax2.plot(his.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.1 1.  1.1]\n",
      "  [2.2 1.8 1.2]]\n",
      "\n",
      " [[1.1 1.2 1.1]\n",
      "  [2.  1.6 1.2]]], shape=(2, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1.1       2.1       3.1999998]\n",
      "  [2.2       4.        5.2      ]]\n",
      "\n",
      " [[1.1       2.3000002 3.4      ]\n",
      "  [2.        3.6       4.8      ]]], shape=(2, 2, 3), dtype=float32)\n",
      "tf.Tensor(0.47631392, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class TorsionLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, size):\n",
    "        super(TorsionLoss,self).__init__()\n",
    "        self.size = size\n",
    "         \n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.transpose(y_true, perm=[0,2,1])\n",
    "        y_pred = tf.transpose(y_pred, perm=[0,2,1])\n",
    "        \n",
    "        print(y_true)\n",
    "        y_true_csum = tf.keras.backend.cumsum(y_true, axis=-1)\n",
    "        y_pred_csum = tf.keras.backend.cumsum(y_pred, axis=-1)\n",
    "        print(y_true_csum)\n",
    "        \n",
    "        y_true_mat_0 = tf.keras.backend.repeat(y_true[:,0,:], self.size)\n",
    "        y_true_mat_1 = tf.keras.backend.repeat(y_true[:,1,:], self.size)\n",
    "        y_pred_mat_0 = tf.keras.backend.repeat(y_pred[:,0,:], self.size)\n",
    "        y_pred_mat_1 = tf.keras.backend.repeat(y_pred[:,1,:], self.size)\n",
    "        \n",
    "\n",
    "        y_pred_mat_0 = tf.transpose(y_pred_mat_0, perm=[0,2,1])\n",
    "        y_pred_mat_1 = tf.transpose(y_pred_mat_1, perm=[0,2,1])\n",
    "\n",
    "        vec_0 = tf.math.squared_difference(y_true_mat_0,y_pred_mat_0)\n",
    "        vec_1 = tf.math.squared_difference(y_true_mat_1,y_pred_mat_1)\n",
    "        \n",
    "        dist_mat = tf.math.add(vec_0, vec_1)\n",
    "        loss = tf.math.reduce_sum(tf.math.l2_normalize(dist_mat),axis=-1)\n",
    "        return loss\n",
    "    \n",
    "pred = tf.reshape(tf.constant([[[1.0,2.1],[1.1, 1.7], [1.1, 1.2]],\n",
    "                               [[1.0,2.1],[1.1, 1.7],[1.1, 1.2]]]),shape=(-1,3,2))\n",
    "true = tf.reshape(tf.constant([[[1.1,2.2],[1.0, 1.8], [1.1,1.2]],\n",
    "                               [[1.1,2.0],[1.2, 1.6],[1.1,1.2]]]),shape=(-1,3,2))\n",
    "\n",
    "loss = TorsionLoss(size=3)\n",
    "\n",
    "l = loss(true,pred)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M_pred, T_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.1415927  -0.97389364]\n",
      " [ 1.6109388  -1.1711161 ]\n",
      " [ 1.0611603  -0.47298384]\n",
      " [ 0.630064   -0.6719518 ]\n",
      " [ 0.3193953  -0.55152416]\n",
      " [ 0.5061455  -0.46774817]\n",
      " [ 0.54454255 -1.0035644 ]\n",
      " [ 1.0978119  -1.3020159 ]\n",
      " [ 1.7191494   2.9146998 ]\n",
      " [ 0.33510327 -0.4066615 ]\n",
      " [ 1.3124878  -0.7103493 ]\n",
      " [ 1.0681417  -0.9093168 ]\n",
      " [ 2.071706   -0.7679448 ]\n",
      " [-1.5184366   2.988004  ]\n",
      " [ 2.0856688  -1.1117749 ]\n",
      " [ 1.8046706  -3.0909784 ]\n",
      " [ 1.6493361   2.9391348 ]\n",
      " [ 1.0594151  -0.741765  ]\n",
      " [ 1.261873   -1.1309733 ]\n",
      " [ 1.5236723  -0.741765  ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[1,0:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.0118482 -2.8887055]\n",
      " [ 2.8379316 -2.970409 ]\n",
      " [ 2.8330193 -2.9651833]\n",
      " [ 2.8345227 -2.9657543]\n",
      " [ 2.83768   -2.9693463]\n",
      " [ 2.8380501 -2.970258 ]\n",
      " [ 2.8330176 -2.9652362]\n",
      " [ 2.8205764 -2.9512446]\n",
      " [ 2.798531  -2.923216 ]\n",
      " [ 2.7660465 -2.8726504]\n",
      " [ 2.7250214 -2.785374 ]\n",
      " [ 2.681994  -2.6457877]\n",
      " [ 2.6486592 -2.476455 ]\n",
      " [ 2.6365578 -2.3885598]\n",
      " [ 2.6489508 -2.4599097]\n",
      " [ 2.6781912 -2.6067867]\n",
      " [ 2.711286  -2.7290199]\n",
      " [ 2.7382298 -2.8045528]\n",
      " [ 2.7559404 -2.845935 ]\n",
      " [ 2.7664514 -2.8673937]]\n"
     ]
    }
   ],
   "source": [
    "print(T_pred[1,:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.277838344000001\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils import layers\n",
    "importlib.reload(layers)\n",
    "batch_size = 2\n",
    "id_ = id_test[0]\n",
    "with tf.device('/cpu:0'):\n",
    "    coord = layers.CoordinalizationCell(batch_size)\n",
    "    layer = tf.keras.layers.RNN(coord, return_sequences=True)\n",
    "\n",
    "    st_1 = tf.constant([[1,-2,0.88] for _ in range(batch_size)])\n",
    "    st_2 = tf.constant([[1,-1.45,0] for _ in range(batch_size)])\n",
    "    st_3 = tf.constant([[1.0,0.0,0.0] for _ in range(batch_size)])\n",
    "\n",
    "\n",
    "    start = time.process_time()\n",
    "    o = layer(Y_test[:batch_size,:300,:], initial_state=[st_1,st_2,st_3])\n",
    "    print(time.process_time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print(T_pred[0,:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-4.3281507e-01  8.8572669e-08 -3.5877639e-01 -4.1480124e-02\n",
      "   4.0720081e-01  3.4816438e-01  3.4425700e-01 -4.5821750e-01\n",
      "  -9.3246156e-01  3.1877762e-01 -9.7524118e-01 -1.0983372e-01]\n",
      " [ 1.1604199e+00 -5.3740174e-01 -2.7723739e-01  5.8450460e-01\n",
      "  -8.7449110e-01 -2.5284171e-02  1.0933622e+00  5.4582655e-02\n",
      "  -2.6674092e-01  5.8092338e-01  3.4222910e-01 -3.7688252e-01]\n",
      " [ 8.0389917e-01  2.3085657e-01  2.4467888e-01  9.7613883e-01\n",
      "   1.7705308e-01 -3.0728415e-01  4.2062163e-01  6.9662601e-02\n",
      "   5.5728424e-01  7.9389381e-01  1.5398926e-01  1.0665975e+00]\n",
      " [ 1.0271344e+00  3.0001640e-02  1.7888629e+00  1.3091011e+00\n",
      "   1.3980989e-01  1.7913237e+00  5.1166070e-01  1.9907989e-03\n",
      "   1.6322256e+00  8.3781624e-01 -8.7077811e-02  2.1252971e+00]\n",
      " [ 7.9311144e-01 -1.3289489e-01  2.6629930e+00  1.0342376e+00\n",
      "  -1.0977556e-01  2.7900226e+00  5.5975997e-01 -9.5739722e-02\n",
      "   2.5427492e+00  6.6098326e-01 -1.0196406e-01  2.6448140e+00]\n",
      " [ 6.6907918e-01 -1.0290749e-01  2.6522350e+00  6.6860998e-01\n",
      "  -1.0290747e-01  2.6521695e+00  6.6272825e-01 -1.0290775e-01\n",
      "   2.6522746e+00  6.6642541e-01 -1.0290777e-01  2.6523111e+00]\n",
      " [ 6.6515034e-01 -1.0290777e-01  2.6523113e+00  6.6568190e-01\n",
      "  -1.0290777e-01  2.6523113e+00  6.6563559e-01 -1.0290777e-01\n",
      "   2.6523113e+00  6.6535312e-01 -1.0290777e-01  2.6523113e+00]\n",
      " [ 6.6545194e-01 -1.0290777e-01  2.6523113e+00  6.6541076e-01\n",
      "  -1.0290777e-01  2.6523113e+00  6.6541433e-01 -1.0290777e-01\n",
      "   2.6523113e+00  6.6543621e-01 -1.0290777e-01  2.6523113e+00]\n",
      " [ 6.6542858e-01 -1.0290777e-01  2.6523113e+00  6.6543174e-01\n",
      "  -1.0290777e-01  2.6523113e+00  6.6543150e-01 -1.0290777e-01\n",
      "   2.6523113e+00  6.6542977e-01 -1.0290777e-01  2.6523113e+00]\n",
      " [ 6.6543037e-01 -1.0290777e-01  2.6523113e+00  6.6543013e-01\n",
      "  -1.0290777e-01  2.6523113e+00  6.6543013e-01 -1.0290777e-01\n",
      "   2.6523113e+00  6.6543025e-01 -1.0290777e-01  2.6523113e+00]], shape=(10, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(o[1,:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={'A': 'Ala',\n",
    "    'C': 'Cys',\n",
    "    'D': 'Asp',\n",
    "    'E': 'Glu',\n",
    "    'F': 'Phe',\n",
    "    'G': 'Gly',\n",
    "    'H': 'His',\n",
    "    'I': 'Ile',\n",
    "    'K': 'Lys',\n",
    "    'L': 'Leu',\n",
    "    'M': 'Met',\n",
    "    'N': 'Asn',\n",
    "    'P': 'Pro',\n",
    "    'Q': 'Gln',\n",
    "    'R': 'Arg',\n",
    "    'S': 'Ser',\n",
    "    'T': 'Thr',\n",
    "    'V': 'Val',\n",
    "    'W': 'Trp',\n",
    "    'Y': 'Tyr',\n",
    "    'X': 'UNK'}\n",
    "\n",
    "# Write PDB\n",
    "\n",
    "#C_C, C_O, C_N, C_Ca\n",
    "f = open(str(id_test[1])+'.pdb', 'w')\n",
    "\n",
    "header_str = \"\"\"PFRMAT TS\\nTARGET T0999\\nAUTHOR 1234-5678-9000\\nREMARK Predictor remarks\\nMETHOD Description of methods used\\nMETHOD Description of methods used\\nMODEL  1 \\nPARENT 1abc 1def_A\\n\"\"\"\n",
    "\n",
    "f.write(header_str)\n",
    "\n",
    "for i in range(len(seq_test[1])):\n",
    "    idx_N  = 4*i\n",
    "    idx_Ca = 1+4*i\n",
    "    idx_C  = 2+4*i\n",
    "    idx_O  = 3+4*i\n",
    "    \n",
    "    res = d[seq_test[1][i]]\n",
    "    \n",
    "    x_N = o[1,i-1,6].numpy() if i > 0 else 1.0\n",
    "    y_N = o[1,i-1,7].numpy() if i > 0 else -1.45\n",
    "    z_N = o[1,i-1,8].numpy() if i > 0 else 0.0\n",
    "    \n",
    "    x_Ca = o[1,i-1,9].numpy() if i > 0 else 1.0\n",
    "    y_Ca = o[1,i-1,10].numpy() if i > 0 else 0.0\n",
    "    z_Ca = o[1,i-1,11].numpy() if i > 0 else 0.0\n",
    "    \n",
    "    x_C = o[1,i,0].numpy()\n",
    "    y_C = o[1,i,1].numpy()\n",
    "    z_C = o[1,i,2].numpy()\n",
    "    \n",
    "    x_O = o[1,i,3].numpy()\n",
    "    y_O = o[1,i,4].numpy()\n",
    "    z_O = o[1,i,5].numpy()\n",
    "    \n",
    "    f.write('ATOM%7d  N%6s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00  \\n'  % (idx_N,  res, i, x_N, y_N, z_N))\n",
    "    f.write('ATOM%7d  Ca%5s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00 \\n' % (idx_Ca, res, i, x_Ca, y_Ca, z_Ca))\n",
    "    f.write('ATOM%7d  C%6s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00  \\n'  % (idx_C,  res, i, x_C, y_C, z_C))\n",
    "    f.write('ATOM%7d  O%6s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00  \\n'  % (idx_O,  res, i, x_O, y_O, z_O))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
