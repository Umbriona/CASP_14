{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Bio import SeqIO\n",
    "from utils import preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "import models\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "path = '../Data_Sets/PDB/FASTA'\n",
    "file_name_m = 'mask_3.fasta'\n",
    "file_name_t = 'mask_torsion.fasta'\n",
    "dict_ = {'id':[] ,'mask':[],'seq':[], 'mask_bin':[], 'seq_bin':[], 'loss_weight':[], 'seq_int':[], 'coord':[], 'angle':[]}\n",
    "count = 0\n",
    "seq_length = 1024\n",
    "d = {'H':1/0.372, 'B':1/0.2105, 'C':1/0.4173}\n",
    "for i, rec in enumerate(SeqIO.parse(os.path.join(path,file_name_m),'fasta')):\n",
    "    \n",
    "    #if i >50000:\n",
    "    #    break\n",
    "    if len(rec.seq)>seq_length:\n",
    "        continue\n",
    "        \n",
    "    #print(rec.id)\n",
    "    dict_['id'].append(rec.id)\n",
    "    dict_['seq'].append(rec.seq)\n",
    "    dict_['seq_int'].append(pre.to_int(rec.seq, max_length=seq_length))\n",
    "    \n",
    "    \n",
    "    \n",
    "    dict_['mask'].append(rec.description.split('|lcl|')[:len(rec.seq)])\n",
    "    dict_['mask_bin'].append(pre.to_binary_mask(pre.mask_padding(rec.description.split('|lcl|')[-1], length=seq_length)))\n",
    "    dict_['loss_weight'].append(pre.loss_weight(rec.description.split('|lcl|')[-1][:len(rec.seq)], d,seq_length))\n",
    "\n",
    "    \n",
    "for k, rec in enumerate(SeqIO.parse(os.path.join(path,file_name_t),'fasta')):\n",
    "        \n",
    "    #if k >50000:\n",
    "    #    break\n",
    "    if len(rec.seq)>seq_length:\n",
    "        continue\n",
    "    #print(rec.id)\n",
    "\n",
    "\n",
    "    f = np.array([ j.split(',')[1:] for j in rec.description.split('|lcl|')[-1].split(';')][1:], dtype=np.float32)\n",
    "    f = ((360+f)%360)/180 * np.pi - np.pi\n",
    "    dict_['angle'].append(pre.zero_padding(f,length=seq_length))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(dict_['seq_int'], dtype = np.int8 ), np.array(dict_['angle'], dtype = np.float32), test_size=0.1, random_state=42)\n",
    "id_train, id_test, seq_train, seq_test = train_test_split(dict_['id'], dict_['seq'], test_size=0.1, random_state=42)\n",
    "W_train, W_test, M_train, M_test = train_test_split(dict_['loss_weight'], dict_['mask_bin'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.1415927 , -0.06806827],\n",
       "       [ 0.8237953 , -2.1170843 ],\n",
       "       [ 1.9041545 ,  2.820452  ],\n",
       "       [ 1.839577  ,  2.6040318 ],\n",
       "       [ 2.1642082 ,  2.5342185 ],\n",
       "       [ 2.0420353 ,  2.490585  ],\n",
       "       [ 1.727876  , -0.32812166],\n",
       "       [ 1.907645  ,  2.9024823 ],\n",
       "       [ 2.2916172 ,  2.3998277 ],\n",
       "       [ 2.0036376 ,  2.6755893 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0,:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "build (None, 64, 256)\n",
      "build (None, 128, 256)\n",
      "build (None, 256, 128)\n",
      "build (None, 512, 64)\n",
      "build (None, 64, 256)\n",
      "build (None, 128, 256)\n",
      "build (None, 256, 128)\n",
      "build (None, 512, 64)\n",
      "Train on 196422 samples, validate on 21825 samples\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 203 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:batch_all_reduce: 203 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "196422/196422 [==============================] - 400s 2ms/sample - loss: 1.2606 - model_loss: 0.4805 - model_1_loss: 0.7506 - val_loss: 1.2264 - val_model_loss: 0.4729 - val_model_1_loss: 0.7241\n",
      "Epoch 2/100\n",
      "196422/196422 [==============================] - 347s 2ms/sample - loss: 1.2599 - model_loss: 0.4805 - model_1_loss: 0.7501 - val_loss: 1.2257 - val_model_loss: 0.4728 - val_model_1_loss: 0.7235\n",
      "Epoch 3/100\n",
      "196422/196422 [==============================] - 347s 2ms/sample - loss: 1.2598 - model_loss: 0.4805 - model_1_loss: 0.7500 - val_loss: 1.2254 - val_model_loss: 0.4728 - val_model_1_loss: 0.7233\n",
      "Epoch 4/100\n",
      "196422/196422 [==============================] - 353s 2ms/sample - loss: 1.2605 - model_loss: 0.4805 - model_1_loss: 0.7505 - val_loss: 1.2249 - val_model_loss: 0.4728 - val_model_1_loss: 0.7229\n",
      "Epoch 5/100\n",
      "196422/196422 [==============================] - 352s 2ms/sample - loss: 1.2603 - model_loss: 0.4806 - model_1_loss: 0.7504 - val_loss: 1.2250 - val_model_loss: 0.4728 - val_model_1_loss: 0.7229\n",
      "Epoch 6/100\n",
      "185344/196422 [===========================>..] - ETA: 19s - loss: 1.2594 - model_loss: 0.4801 - model_1_loss: 0.7499"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a38d04f4f83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Weights_MaskModel/w_tor_mod'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mhis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mM_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlr_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Weights_MaskModel/w_tor_mod'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#li1.append(model.evaluate(x = X_test, y = [M_test,Y_test], batch_size=64, verbose=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/Cyclic_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p1 = {'max_seq_len': seq_length,\n",
    "     'num_classes': 3,\n",
    "     'emb_size': 20,\n",
    "     'num_filter': [32, 64, 128, 256, 512],\n",
    "     'kernel_size':[4, 4, 4, 4, 4] ,\n",
    "     'sampling_stride': [2, 2, 2, 2],\n",
    "     'pool_size': [2, 2, 2, 2, 2, 2],\n",
    "     'rate': [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "     'l1': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "     'l2': [0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "     'use_max_pool': False,\n",
    "     'learning_rate': 1e-4,\n",
    "    'output_activation': 'softmax'}\n",
    "p2 = {'max_seq_len': seq_length,\n",
    "     'num_classes': 32,\n",
    "     'emb_size': 10,\n",
    "     'num_filter': [32, 64, 128, 256, 512],\n",
    "     'kernel_size':[4, 4, 4, 4, 4] ,\n",
    "     'sampling_stride': [2, 2, 2, 2],\n",
    "     'pool_size': [2, 2, 2, 2, 2, 2],\n",
    "     'rate': [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "     'l1': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "     'l2': [0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "     'use_max_pool': False,\n",
    "     'learning_rate': 1e-4,\n",
    "    'output_activation': 'softmax',\n",
    "     'features':32}\n",
    "\n",
    "\n",
    "def casp_loss(y_pred, y_true):\n",
    "    return 0\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model1 = models.res_u_net(p1)\n",
    "    model2 = models.res_u_net_tor(p2)\n",
    "\n",
    "\n",
    "    model1.load_weights('Weights_MaskModel/w_LDataset')\n",
    "\n",
    "    inp1 = tf.keras.layers.Input(shape=(seq_length))\n",
    "    out1, x_o = model1(inp1)\n",
    "    x1 = tf.keras.layers.Conv1D(32, 7, padding='same')(out1)\n",
    "    x2 = tf.keras.layers.Conv1D(32, 7, padding='same')(x_o)\n",
    "    inp2 = tf.keras.layers.Add()([x1,x2])\n",
    "    out2 = model2(inp2)\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs = inp1, outputs = [out1,out2])\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    add_1 = tf.keras.optimizers.Adam(learning_rate=1e-4,name='Adam_1')\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=False, name='SGD')\n",
    "    \n",
    "    # Callbacks for Adam optimization\n",
    "    lr_2 = tf.keras.callbacks.ReduceLROnPlateau(monitor='model_1_loss', factor=0.2, patience=5, verbose=1, mode='auto',\n",
    "    min_delta=0.0001, min_lr=0.0000001)\n",
    "\n",
    "    # compiling and fitting with Adam optimizer\n",
    "    model.compile(optimizer = add_1, loss = [cce, mse], sample_weight_mode=\"temporal\")\n",
    "    his = []\n",
    "    li1 = []\n",
    "    model.load_weights('Weights_MaskModel/w_tor_mod')\n",
    "    for u in range(10):\n",
    "        his.append(model.fit(X_train, [M_train, Y_train], batch_size=128, epochs= 100, callbacks= [lr_2], validation_split=0.1, sample_weight = [ np.array(W_train),np.array(W_train)]))\n",
    "        model.save_weights('Weights_MaskModel/w_tor_mod')\n",
    "        #li1.append(model.evaluate(x = X_test, y = [M_test,Y_test], batch_size=64, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Weights_MaskModel/w_tor_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.load_weights('Weights_MaskModel/w_tor_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9ff149d6fbd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_model_1_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.plot(his[1].history['loss'])\n",
    "ax1.plot(his[1].history['val_loss'])\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.plot(his[0].history['val_model_1_loss'])\n",
    "ax2.set_ylim([0,1])\n",
    "plt.show()\n",
    "#ax2.plot(his.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M_pred, T_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.1415927  -2.0996308 ]\n",
      " [ 1.0437071  -1.1065388 ]\n",
      " [ 1.7191494  -1.1135199 ]\n",
      " [ 1.3788102   1.3561213 ]\n",
      " [ 1.3264506   3.0543263 ]\n",
      " [ 0.64577174 -2.3108158 ]\n",
      " [ 1.8133972   0.38571787]\n",
      " [ 1.0698869  -1.0855949 ]\n",
      " [ 1.3194692  -2.7192228 ]\n",
      " [ 1.923353    2.637193  ]\n",
      " [ 1.88321     2.9007375 ]\n",
      " [-1.9949112  -2.9722955 ]\n",
      " [ 0.35953808 -2.4993117 ]\n",
      " [ 1.8099067  -0.26179934]\n",
      " [ 1.1431906  -2.9932396 ]\n",
      " [-2.2567105   0.47822   ]\n",
      " [ 1.3491395   1.8692477 ]\n",
      " [ 0.35255647 -1.1431906 ]\n",
      " [-1.7592918  -2.347468  ]\n",
      " [ 0.6126108  -1.0419617 ]\n",
      " [ 1.5603244  -0.49741888]\n",
      " [ 1.5882494  -0.6614797 ]\n",
      " [ 1.2164943  -0.912807  ]\n",
      " [ 1.8291047   2.59705   ]\n",
      " [ 1.7976892   2.628466  ]\n",
      " [ 1.3840458   2.820452  ]\n",
      " [-1.9652408  -2.5673795 ]\n",
      " [ 0.35430193 -0.38048148]\n",
      " [ 1.9303343  -0.71383953]\n",
      " [ 0.827286    0.20071292]\n",
      " [ 1.9826944  -0.69638634]\n",
      " [ 1.5795233  -0.5131266 ]\n",
      " [ 0.93375134 -1.9966567 ]\n",
      " [ 1.8936822  -3.1415927 ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[1,0:60,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5694499  -0.07142629]\n",
      " [ 1.1019993  -0.4641437 ]\n",
      " [ 1.1536447  -0.4636875 ]\n",
      " [ 1.1582164  -0.71167773]\n",
      " [ 1.3528682  -0.24029587]\n",
      " [ 1.3331226   0.3723785 ]\n",
      " [ 1.214086   -0.04831442]\n",
      " [ 1.1909322  -0.00558217]\n",
      " [-0.05876413  0.20209552]\n",
      " [ 1.18658     0.03710468]\n",
      " [ 1.3041048  -0.30202124]\n",
      " [ 1.976822    2.2719412 ]\n",
      " [ 1.9849423   2.3608065 ]\n",
      " [ 1.9852419   2.3740468 ]\n",
      " [ 1.9965765   2.3704994 ]\n",
      " [ 1.9982369   2.3911493 ]\n",
      " [ 1.9992958   2.3874564 ]\n",
      " [ 1.9918451   2.359342  ]\n",
      " [ 1.9727976   2.3354316 ]\n",
      " [ 1.9440486   2.2809985 ]]\n"
     ]
    }
   ],
   "source": [
    "print(T_pred[2,:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7790894330028095\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils import layers\n",
    "importlib.reload(layers)\n",
    "batch_size = 2\n",
    "id_ = id_test[]\n",
    "with tf.device('/cpu:0'):\n",
    "    coord = layers.CoordinalizationCell(batch_size)\n",
    "    layer = tf.keras.layers.RNN(coord, return_sequences=True)\n",
    "\n",
    "    st_1 = tf.constant([[1,-2,0.88] for _ in range(batch_size)])\n",
    "    st_2 = tf.constant([[1,-1.45,0] for _ in range(batch_size)])\n",
    "    st_3 = tf.constant([[1.0,0.0,0.0] for _ in range(batch_size)])\n",
    "\n",
    "\n",
    "    start = time.process_time()\n",
    "    o = layer(T_pred[:batch_size,:100,:], initial_state=[st_1,st_2,st_3])\n",
    "    print(time.process_time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print(T_pred[0,:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.91375023 -1.011316   -0.3587764   1.619928   -0.84655803  0.10140276\n",
      "   0.19238216 -1.3405133   0.02241895  0.91896635 -1.7761297   0.04365367]\n",
      " [ 0.49048138 -1.9463615   0.91900396  1.1211524  -2.024556    1.4422748\n",
      "   0.14487088 -1.399015    0.757228   -0.16383687 -1.5725883   1.6585152 ]\n",
      " [ 0.7682673  -1.8373079   1.9136522   0.6345812  -2.4289954   1.2810291\n",
      "   0.12671101 -1.408424    2.3914182   0.10063181 -1.0573208   3.651332  ]\n",
      " [ 1.2715977  -1.2192838   2.8839977   1.2443488  -0.16738832  2.4104252\n",
      "   0.30731273 -1.7387726   3.4726949   1.3525702  -2.5546887   3.8208256 ]\n",
      " [ 1.4929587  -3.7336206   4.677298    0.5084049  -3.3086042   5.1999474\n",
      "   2.4815788  -2.9993603   4.349376    1.2220814  -3.242465    3.7687316 ]\n",
      " [ 1.0912082  -2.0897303   4.708447    0.75905204 -2.9402437   5.513897\n",
      "   1.57618    -2.3648612   3.5167463   1.550177   -0.9717548   3.9018998 ]\n",
      " [ 1.4048853  -2.0657468   2.8602426   0.61925244 -1.6098353   3.6879904\n",
      "   2.4123998  -2.85092     3.1851418   2.5573592  -3.7991138   4.27125   ]\n",
      " [ 3.3200252  -2.8122835   3.4035842   2.1037693  -2.7477033   3.2358792\n",
      "   4.0406394  -1.7956582   3.837405    2.6741085  -1.3238622   3.9414985 ]\n",
      " [ 3.383365   -2.002377    5.101761    3.8981376  -2.7233417   4.248614\n",
      "   2.2014558  -2.250145    5.6343203   3.1202676  -2.4645333   6.735264  ]\n",
      " [ 2.5629287  -2.5083694   8.148705    2.6661077  -2.0224006   9.273909\n",
      "   2.9203832  -1.8657551   7.0525002   2.113667   -1.0105996   7.9012704 ]], shape=(10, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(o[0,:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={'A': 'Ala',\n",
    "    'C': 'Cys',\n",
    "    'D': 'Asp',\n",
    "    'E': 'Glu',\n",
    "    'F': 'Phe',\n",
    "    'G': 'Gly',\n",
    "    'H': 'His',\n",
    "    'I': 'Ile',\n",
    "    'K': 'Lys',\n",
    "    'L': 'Leu',\n",
    "    'M': 'Met',\n",
    "    'N': 'Asn',\n",
    "    'P': 'Pro',\n",
    "    'Q': 'Gln',\n",
    "    'R': 'Arg',\n",
    "    'S': 'Ser',\n",
    "    'T': 'Thr',\n",
    "    'V': 'Val',\n",
    "    'W': 'Trp',\n",
    "    'Y': 'Tyr',\n",
    "    'X': 'UNK'}\n",
    "\n",
    "# Write PDB\n",
    "\n",
    "#C_C, C_O, C_N, C_Ca\n",
    "f = open(str(id_test[0])+'.pdb', 'w')\n",
    "\n",
    "header_str = \"\"\"PFRMAT TS\\nTARGET T0999\\nAUTHOR 1234-5678-9000\\nREMARK Predictor remarks\\nMETHOD Description of methods used\\nMETHOD Description of methods used\\nMODEL  1 \\nPARENT 1abc 1def_A\\n\"\"\"\n",
    "\n",
    "f.write(header_str)\n",
    "\n",
    "for i in range(len(seq_test[0])):\n",
    "    idx_N  = 4*i\n",
    "    idx_Ca = 1+4*i\n",
    "    idx_C  = 2+4*i\n",
    "    idx_O  = 3+4*i\n",
    "    \n",
    "    res = d[seq_test[0][i]]\n",
    "    \n",
    "    x_N = o[0,i-1,6].numpy() if i > 0 else 1.0\n",
    "    y_N = o[0,i-1,7].numpy() if i > 0 else -1.45\n",
    "    z_N = o[0,i-1,8].numpy() if i > 0 else 0.0\n",
    "    \n",
    "    x_Ca = o[0,i-1,9].numpy() if i > 0 else 1.0\n",
    "    y_Ca = o[0,i-1,10].numpy() if i > 0 else 0.0\n",
    "    z_Ca = o[0,i-1,11].numpy() if i > 0 else 0.0\n",
    "    \n",
    "    x_C = o[0,i,0].numpy()\n",
    "    y_C = o[0,i,1].numpy()\n",
    "    z_C = o[0,i,2].numpy()\n",
    "    \n",
    "    x_O = o[0,i,3].numpy()\n",
    "    y_O = o[0,i,4].numpy()\n",
    "    z_O = o[0,i,5].numpy()\n",
    "    \n",
    "    f.write('ATOM%7d  N%6s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00  \\n'  % (idx_N,  res, i, x_N, y_N, z_N))\n",
    "    f.write('ATOM%7d  Ca%5s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00 \\n' % (idx_Ca, res, i, x_Ca, y_Ca, z_Ca))\n",
    "    f.write('ATOM%7d  C%6s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00  \\n'  % (idx_C,  res, i, x_C, y_C, z_C))\n",
    "    f.write('ATOM%7d  O%6s A%4d% 12.3f% 8.3f% 8.3f  1.00  0.00  \\n'  % (idx_O,  res, i, x_O, y_O, z_O))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
